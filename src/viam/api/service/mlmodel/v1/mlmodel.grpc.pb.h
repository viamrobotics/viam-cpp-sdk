// Generated by the gRPC C++ plugin.
// If you make any local change, they will be lost.
// source: service/mlmodel/v1/mlmodel.proto
#ifndef GRPC_service_2fmlmodel_2fv1_2fmlmodel_2eproto__INCLUDED
#define GRPC_service_2fmlmodel_2fv1_2fmlmodel_2eproto__INCLUDED

#include "service/mlmodel/v1/mlmodel.pb.h"

#include <functional>
#include <grpc/impl/codegen/port_platform.h>
#include <grpcpp/impl/codegen/async_generic_service.h>
#include <grpcpp/impl/codegen/async_stream.h>
#include <grpcpp/impl/codegen/async_unary_call.h>
#include <grpcpp/impl/codegen/client_callback.h>
#include <grpcpp/impl/codegen/client_context.h>
#include <grpcpp/impl/codegen/completion_queue.h>
#include <grpcpp/impl/codegen/message_allocator.h>
#include <grpcpp/impl/codegen/method_handler.h>
#include <grpcpp/impl/codegen/proto_utils.h>
#include <grpcpp/impl/codegen/rpc_method.h>
#include <grpcpp/impl/codegen/server_callback.h>
#include <grpcpp/impl/codegen/server_callback_handlers.h>
#include <grpcpp/impl/codegen/server_context.h>
#include <grpcpp/impl/codegen/service_type.h>
#include <grpcpp/impl/codegen/status.h>
#include <grpcpp/impl/codegen/stub_options.h>
#include <grpcpp/impl/codegen/sync_stream.h>

namespace viam {
namespace service {
namespace mlmodel {
namespace v1 {

// MLModelService declares the gRPC contract for a service that takes in a map of input arrays/tensors,
// runs them through an ML inference engine, and outputs a map of array/tensors.
class MLModelService final {
 public:
  static constexpr char const* service_full_name() {
    return "viam.service.mlmodel.v1.MLModelService";
  }
  class StubInterface {
   public:
    virtual ~StubInterface() {}
    // Infer takes an already ordered input tensor as a map, makes an inference on the model, and returns an output data map.
    virtual ::grpc::Status Infer(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::InferRequest& request, ::viam::service::mlmodel::v1::InferResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::viam::service::mlmodel::v1::InferResponse>> AsyncInfer(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::InferRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::viam::service::mlmodel::v1::InferResponse>>(AsyncInferRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::viam::service::mlmodel::v1::InferResponse>> PrepareAsyncInfer(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::InferRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::viam::service::mlmodel::v1::InferResponse>>(PrepareAsyncInferRaw(context, request, cq));
    }
    // Metadata returns the metadata associated with the ML model.
    virtual ::grpc::Status Metadata(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::MetadataRequest& request, ::viam::service::mlmodel::v1::MetadataResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::viam::service::mlmodel::v1::MetadataResponse>> AsyncMetadata(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::MetadataRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::viam::service::mlmodel::v1::MetadataResponse>>(AsyncMetadataRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::viam::service::mlmodel::v1::MetadataResponse>> PrepareAsyncMetadata(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::MetadataRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::viam::service::mlmodel::v1::MetadataResponse>>(PrepareAsyncMetadataRaw(context, request, cq));
    }
    class experimental_async_interface {
     public:
      virtual ~experimental_async_interface() {}
      // Infer takes an already ordered input tensor as a map, makes an inference on the model, and returns an output data map.
      virtual void Infer(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::InferRequest* request, ::viam::service::mlmodel::v1::InferResponse* response, std::function<void(::grpc::Status)>) = 0;
      virtual void Infer(::grpc::ClientContext* context, const ::grpc::ByteBuffer* request, ::viam::service::mlmodel::v1::InferResponse* response, std::function<void(::grpc::Status)>) = 0;
      #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
      virtual void Infer(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::InferRequest* request, ::viam::service::mlmodel::v1::InferResponse* response, ::grpc::ClientUnaryReactor* reactor) = 0;
      #else
      virtual void Infer(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::InferRequest* request, ::viam::service::mlmodel::v1::InferResponse* response, ::grpc::experimental::ClientUnaryReactor* reactor) = 0;
      #endif
      #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
      virtual void Infer(::grpc::ClientContext* context, const ::grpc::ByteBuffer* request, ::viam::service::mlmodel::v1::InferResponse* response, ::grpc::ClientUnaryReactor* reactor) = 0;
      #else
      virtual void Infer(::grpc::ClientContext* context, const ::grpc::ByteBuffer* request, ::viam::service::mlmodel::v1::InferResponse* response, ::grpc::experimental::ClientUnaryReactor* reactor) = 0;
      #endif
      // Metadata returns the metadata associated with the ML model.
      virtual void Metadata(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::MetadataRequest* request, ::viam::service::mlmodel::v1::MetadataResponse* response, std::function<void(::grpc::Status)>) = 0;
      virtual void Metadata(::grpc::ClientContext* context, const ::grpc::ByteBuffer* request, ::viam::service::mlmodel::v1::MetadataResponse* response, std::function<void(::grpc::Status)>) = 0;
      #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
      virtual void Metadata(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::MetadataRequest* request, ::viam::service::mlmodel::v1::MetadataResponse* response, ::grpc::ClientUnaryReactor* reactor) = 0;
      #else
      virtual void Metadata(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::MetadataRequest* request, ::viam::service::mlmodel::v1::MetadataResponse* response, ::grpc::experimental::ClientUnaryReactor* reactor) = 0;
      #endif
      #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
      virtual void Metadata(::grpc::ClientContext* context, const ::grpc::ByteBuffer* request, ::viam::service::mlmodel::v1::MetadataResponse* response, ::grpc::ClientUnaryReactor* reactor) = 0;
      #else
      virtual void Metadata(::grpc::ClientContext* context, const ::grpc::ByteBuffer* request, ::viam::service::mlmodel::v1::MetadataResponse* response, ::grpc::experimental::ClientUnaryReactor* reactor) = 0;
      #endif
    };
    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
    typedef class experimental_async_interface async_interface;
    #endif
    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
    async_interface* async() { return experimental_async(); }
    #endif
    virtual class experimental_async_interface* experimental_async() { return nullptr; }
  private:
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::viam::service::mlmodel::v1::InferResponse>* AsyncInferRaw(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::InferRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::viam::service::mlmodel::v1::InferResponse>* PrepareAsyncInferRaw(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::InferRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::viam::service::mlmodel::v1::MetadataResponse>* AsyncMetadataRaw(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::MetadataRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::viam::service::mlmodel::v1::MetadataResponse>* PrepareAsyncMetadataRaw(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::MetadataRequest& request, ::grpc::CompletionQueue* cq) = 0;
  };
  class Stub final : public StubInterface {
   public:
    Stub(const std::shared_ptr< ::grpc::ChannelInterface>& channel);
    ::grpc::Status Infer(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::InferRequest& request, ::viam::service::mlmodel::v1::InferResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::viam::service::mlmodel::v1::InferResponse>> AsyncInfer(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::InferRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::viam::service::mlmodel::v1::InferResponse>>(AsyncInferRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::viam::service::mlmodel::v1::InferResponse>> PrepareAsyncInfer(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::InferRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::viam::service::mlmodel::v1::InferResponse>>(PrepareAsyncInferRaw(context, request, cq));
    }
    ::grpc::Status Metadata(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::MetadataRequest& request, ::viam::service::mlmodel::v1::MetadataResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::viam::service::mlmodel::v1::MetadataResponse>> AsyncMetadata(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::MetadataRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::viam::service::mlmodel::v1::MetadataResponse>>(AsyncMetadataRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::viam::service::mlmodel::v1::MetadataResponse>> PrepareAsyncMetadata(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::MetadataRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::viam::service::mlmodel::v1::MetadataResponse>>(PrepareAsyncMetadataRaw(context, request, cq));
    }
    class experimental_async final :
      public StubInterface::experimental_async_interface {
     public:
      void Infer(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::InferRequest* request, ::viam::service::mlmodel::v1::InferResponse* response, std::function<void(::grpc::Status)>) override;
      void Infer(::grpc::ClientContext* context, const ::grpc::ByteBuffer* request, ::viam::service::mlmodel::v1::InferResponse* response, std::function<void(::grpc::Status)>) override;
      #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
      void Infer(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::InferRequest* request, ::viam::service::mlmodel::v1::InferResponse* response, ::grpc::ClientUnaryReactor* reactor) override;
      #else
      void Infer(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::InferRequest* request, ::viam::service::mlmodel::v1::InferResponse* response, ::grpc::experimental::ClientUnaryReactor* reactor) override;
      #endif
      #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
      void Infer(::grpc::ClientContext* context, const ::grpc::ByteBuffer* request, ::viam::service::mlmodel::v1::InferResponse* response, ::grpc::ClientUnaryReactor* reactor) override;
      #else
      void Infer(::grpc::ClientContext* context, const ::grpc::ByteBuffer* request, ::viam::service::mlmodel::v1::InferResponse* response, ::grpc::experimental::ClientUnaryReactor* reactor) override;
      #endif
      void Metadata(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::MetadataRequest* request, ::viam::service::mlmodel::v1::MetadataResponse* response, std::function<void(::grpc::Status)>) override;
      void Metadata(::grpc::ClientContext* context, const ::grpc::ByteBuffer* request, ::viam::service::mlmodel::v1::MetadataResponse* response, std::function<void(::grpc::Status)>) override;
      #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
      void Metadata(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::MetadataRequest* request, ::viam::service::mlmodel::v1::MetadataResponse* response, ::grpc::ClientUnaryReactor* reactor) override;
      #else
      void Metadata(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::MetadataRequest* request, ::viam::service::mlmodel::v1::MetadataResponse* response, ::grpc::experimental::ClientUnaryReactor* reactor) override;
      #endif
      #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
      void Metadata(::grpc::ClientContext* context, const ::grpc::ByteBuffer* request, ::viam::service::mlmodel::v1::MetadataResponse* response, ::grpc::ClientUnaryReactor* reactor) override;
      #else
      void Metadata(::grpc::ClientContext* context, const ::grpc::ByteBuffer* request, ::viam::service::mlmodel::v1::MetadataResponse* response, ::grpc::experimental::ClientUnaryReactor* reactor) override;
      #endif
     private:
      friend class Stub;
      explicit experimental_async(Stub* stub): stub_(stub) { }
      Stub* stub() { return stub_; }
      Stub* stub_;
    };
    class experimental_async_interface* experimental_async() override { return &async_stub_; }

   private:
    std::shared_ptr< ::grpc::ChannelInterface> channel_;
    class experimental_async async_stub_{this};
    ::grpc::ClientAsyncResponseReader< ::viam::service::mlmodel::v1::InferResponse>* AsyncInferRaw(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::InferRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::viam::service::mlmodel::v1::InferResponse>* PrepareAsyncInferRaw(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::InferRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::viam::service::mlmodel::v1::MetadataResponse>* AsyncMetadataRaw(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::MetadataRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::viam::service::mlmodel::v1::MetadataResponse>* PrepareAsyncMetadataRaw(::grpc::ClientContext* context, const ::viam::service::mlmodel::v1::MetadataRequest& request, ::grpc::CompletionQueue* cq) override;
    const ::grpc::internal::RpcMethod rpcmethod_Infer_;
    const ::grpc::internal::RpcMethod rpcmethod_Metadata_;
  };
  static std::unique_ptr<Stub> NewStub(const std::shared_ptr< ::grpc::ChannelInterface>& channel, const ::grpc::StubOptions& options = ::grpc::StubOptions());

  class Service : public ::grpc::Service {
   public:
    Service();
    virtual ~Service();
    // Infer takes an already ordered input tensor as a map, makes an inference on the model, and returns an output data map.
    virtual ::grpc::Status Infer(::grpc::ServerContext* context, const ::viam::service::mlmodel::v1::InferRequest* request, ::viam::service::mlmodel::v1::InferResponse* response);
    // Metadata returns the metadata associated with the ML model.
    virtual ::grpc::Status Metadata(::grpc::ServerContext* context, const ::viam::service::mlmodel::v1::MetadataRequest* request, ::viam::service::mlmodel::v1::MetadataResponse* response);
  };
  template <class BaseClass>
  class WithAsyncMethod_Infer : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithAsyncMethod_Infer() {
      ::grpc::Service::MarkMethodAsync(0);
    }
    ~WithAsyncMethod_Infer() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Infer(::grpc::ServerContext* /*context*/, const ::viam::service::mlmodel::v1::InferRequest* /*request*/, ::viam::service::mlmodel::v1::InferResponse* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestInfer(::grpc::ServerContext* context, ::viam::service::mlmodel::v1::InferRequest* request, ::grpc::ServerAsyncResponseWriter< ::viam::service::mlmodel::v1::InferResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(0, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithAsyncMethod_Metadata : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithAsyncMethod_Metadata() {
      ::grpc::Service::MarkMethodAsync(1);
    }
    ~WithAsyncMethod_Metadata() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Metadata(::grpc::ServerContext* /*context*/, const ::viam::service::mlmodel::v1::MetadataRequest* /*request*/, ::viam::service::mlmodel::v1::MetadataResponse* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestMetadata(::grpc::ServerContext* context, ::viam::service::mlmodel::v1::MetadataRequest* request, ::grpc::ServerAsyncResponseWriter< ::viam::service::mlmodel::v1::MetadataResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(1, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  typedef WithAsyncMethod_Infer<WithAsyncMethod_Metadata<Service > > AsyncService;
  template <class BaseClass>
  class ExperimentalWithCallbackMethod_Infer : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    ExperimentalWithCallbackMethod_Infer() {
    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
      ::grpc::Service::
    #else
      ::grpc::Service::experimental().
    #endif
        MarkMethodCallback(0,
          new ::grpc_impl::internal::CallbackUnaryHandler< ::viam::service::mlmodel::v1::InferRequest, ::viam::service::mlmodel::v1::InferResponse>(
            [this](
    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
                   ::grpc::CallbackServerContext*
    #else
                   ::grpc::experimental::CallbackServerContext*
    #endif
                     context, const ::viam::service::mlmodel::v1::InferRequest* request, ::viam::service::mlmodel::v1::InferResponse* response) { return this->Infer(context, request, response); }));}
    void SetMessageAllocatorFor_Infer(
        ::grpc::experimental::MessageAllocator< ::viam::service::mlmodel::v1::InferRequest, ::viam::service::mlmodel::v1::InferResponse>* allocator) {
    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
      ::grpc::internal::MethodHandler* const handler = ::grpc::Service::GetHandler(0);
    #else
      ::grpc::internal::MethodHandler* const handler = ::grpc::Service::experimental().GetHandler(0);
    #endif
      static_cast<::grpc_impl::internal::CallbackUnaryHandler< ::viam::service::mlmodel::v1::InferRequest, ::viam::service::mlmodel::v1::InferResponse>*>(handler)
              ->SetMessageAllocator(allocator);
    }
    ~ExperimentalWithCallbackMethod_Infer() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Infer(::grpc::ServerContext* /*context*/, const ::viam::service::mlmodel::v1::InferRequest* /*request*/, ::viam::service::mlmodel::v1::InferResponse* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
    virtual ::grpc::ServerUnaryReactor* Infer(
      ::grpc::CallbackServerContext* /*context*/, const ::viam::service::mlmodel::v1::InferRequest* /*request*/, ::viam::service::mlmodel::v1::InferResponse* /*response*/)
    #else
    virtual ::grpc::experimental::ServerUnaryReactor* Infer(
      ::grpc::experimental::CallbackServerContext* /*context*/, const ::viam::service::mlmodel::v1::InferRequest* /*request*/, ::viam::service::mlmodel::v1::InferResponse* /*response*/)
    #endif
      { return nullptr; }
  };
  template <class BaseClass>
  class ExperimentalWithCallbackMethod_Metadata : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    ExperimentalWithCallbackMethod_Metadata() {
    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
      ::grpc::Service::
    #else
      ::grpc::Service::experimental().
    #endif
        MarkMethodCallback(1,
          new ::grpc_impl::internal::CallbackUnaryHandler< ::viam::service::mlmodel::v1::MetadataRequest, ::viam::service::mlmodel::v1::MetadataResponse>(
            [this](
    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
                   ::grpc::CallbackServerContext*
    #else
                   ::grpc::experimental::CallbackServerContext*
    #endif
                     context, const ::viam::service::mlmodel::v1::MetadataRequest* request, ::viam::service::mlmodel::v1::MetadataResponse* response) { return this->Metadata(context, request, response); }));}
    void SetMessageAllocatorFor_Metadata(
        ::grpc::experimental::MessageAllocator< ::viam::service::mlmodel::v1::MetadataRequest, ::viam::service::mlmodel::v1::MetadataResponse>* allocator) {
    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
      ::grpc::internal::MethodHandler* const handler = ::grpc::Service::GetHandler(1);
    #else
      ::grpc::internal::MethodHandler* const handler = ::grpc::Service::experimental().GetHandler(1);
    #endif
      static_cast<::grpc_impl::internal::CallbackUnaryHandler< ::viam::service::mlmodel::v1::MetadataRequest, ::viam::service::mlmodel::v1::MetadataResponse>*>(handler)
              ->SetMessageAllocator(allocator);
    }
    ~ExperimentalWithCallbackMethod_Metadata() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Metadata(::grpc::ServerContext* /*context*/, const ::viam::service::mlmodel::v1::MetadataRequest* /*request*/, ::viam::service::mlmodel::v1::MetadataResponse* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
    virtual ::grpc::ServerUnaryReactor* Metadata(
      ::grpc::CallbackServerContext* /*context*/, const ::viam::service::mlmodel::v1::MetadataRequest* /*request*/, ::viam::service::mlmodel::v1::MetadataResponse* /*response*/)
    #else
    virtual ::grpc::experimental::ServerUnaryReactor* Metadata(
      ::grpc::experimental::CallbackServerContext* /*context*/, const ::viam::service::mlmodel::v1::MetadataRequest* /*request*/, ::viam::service::mlmodel::v1::MetadataResponse* /*response*/)
    #endif
      { return nullptr; }
  };
  #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
  typedef ExperimentalWithCallbackMethod_Infer<ExperimentalWithCallbackMethod_Metadata<Service > > CallbackService;
  #endif

  typedef ExperimentalWithCallbackMethod_Infer<ExperimentalWithCallbackMethod_Metadata<Service > > ExperimentalCallbackService;
  template <class BaseClass>
  class WithGenericMethod_Infer : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithGenericMethod_Infer() {
      ::grpc::Service::MarkMethodGeneric(0);
    }
    ~WithGenericMethod_Infer() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Infer(::grpc::ServerContext* /*context*/, const ::viam::service::mlmodel::v1::InferRequest* /*request*/, ::viam::service::mlmodel::v1::InferResponse* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithGenericMethod_Metadata : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithGenericMethod_Metadata() {
      ::grpc::Service::MarkMethodGeneric(1);
    }
    ~WithGenericMethod_Metadata() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Metadata(::grpc::ServerContext* /*context*/, const ::viam::service::mlmodel::v1::MetadataRequest* /*request*/, ::viam::service::mlmodel::v1::MetadataResponse* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithRawMethod_Infer : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithRawMethod_Infer() {
      ::grpc::Service::MarkMethodRaw(0);
    }
    ~WithRawMethod_Infer() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Infer(::grpc::ServerContext* /*context*/, const ::viam::service::mlmodel::v1::InferRequest* /*request*/, ::viam::service::mlmodel::v1::InferResponse* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestInfer(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(0, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawMethod_Metadata : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithRawMethod_Metadata() {
      ::grpc::Service::MarkMethodRaw(1);
    }
    ~WithRawMethod_Metadata() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Metadata(::grpc::ServerContext* /*context*/, const ::viam::service::mlmodel::v1::MetadataRequest* /*request*/, ::viam::service::mlmodel::v1::MetadataResponse* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestMetadata(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(1, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class ExperimentalWithRawCallbackMethod_Infer : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    ExperimentalWithRawCallbackMethod_Infer() {
    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
      ::grpc::Service::
    #else
      ::grpc::Service::experimental().
    #endif
        MarkMethodRawCallback(0,
          new ::grpc_impl::internal::CallbackUnaryHandler< ::grpc::ByteBuffer, ::grpc::ByteBuffer>(
            [this](
    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
                   ::grpc::CallbackServerContext*
    #else
                   ::grpc::experimental::CallbackServerContext*
    #endif
                     context, const ::grpc::ByteBuffer* request, ::grpc::ByteBuffer* response) { return this->Infer(context, request, response); }));
    }
    ~ExperimentalWithRawCallbackMethod_Infer() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Infer(::grpc::ServerContext* /*context*/, const ::viam::service::mlmodel::v1::InferRequest* /*request*/, ::viam::service::mlmodel::v1::InferResponse* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
    virtual ::grpc::ServerUnaryReactor* Infer(
      ::grpc::CallbackServerContext* /*context*/, const ::grpc::ByteBuffer* /*request*/, ::grpc::ByteBuffer* /*response*/)
    #else
    virtual ::grpc::experimental::ServerUnaryReactor* Infer(
      ::grpc::experimental::CallbackServerContext* /*context*/, const ::grpc::ByteBuffer* /*request*/, ::grpc::ByteBuffer* /*response*/)
    #endif
      { return nullptr; }
  };
  template <class BaseClass>
  class ExperimentalWithRawCallbackMethod_Metadata : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    ExperimentalWithRawCallbackMethod_Metadata() {
    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
      ::grpc::Service::
    #else
      ::grpc::Service::experimental().
    #endif
        MarkMethodRawCallback(1,
          new ::grpc_impl::internal::CallbackUnaryHandler< ::grpc::ByteBuffer, ::grpc::ByteBuffer>(
            [this](
    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
                   ::grpc::CallbackServerContext*
    #else
                   ::grpc::experimental::CallbackServerContext*
    #endif
                     context, const ::grpc::ByteBuffer* request, ::grpc::ByteBuffer* response) { return this->Metadata(context, request, response); }));
    }
    ~ExperimentalWithRawCallbackMethod_Metadata() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Metadata(::grpc::ServerContext* /*context*/, const ::viam::service::mlmodel::v1::MetadataRequest* /*request*/, ::viam::service::mlmodel::v1::MetadataResponse* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL
    virtual ::grpc::ServerUnaryReactor* Metadata(
      ::grpc::CallbackServerContext* /*context*/, const ::grpc::ByteBuffer* /*request*/, ::grpc::ByteBuffer* /*response*/)
    #else
    virtual ::grpc::experimental::ServerUnaryReactor* Metadata(
      ::grpc::experimental::CallbackServerContext* /*context*/, const ::grpc::ByteBuffer* /*request*/, ::grpc::ByteBuffer* /*response*/)
    #endif
      { return nullptr; }
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_Infer : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithStreamedUnaryMethod_Infer() {
      ::grpc::Service::MarkMethodStreamed(0,
        new ::grpc::internal::StreamedUnaryHandler<
          ::viam::service::mlmodel::v1::InferRequest, ::viam::service::mlmodel::v1::InferResponse>(
            [this](::grpc_impl::ServerContext* context,
                   ::grpc_impl::ServerUnaryStreamer<
                     ::viam::service::mlmodel::v1::InferRequest, ::viam::service::mlmodel::v1::InferResponse>* streamer) {
                       return this->StreamedInfer(context,
                         streamer);
                  }));
    }
    ~WithStreamedUnaryMethod_Infer() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status Infer(::grpc::ServerContext* /*context*/, const ::viam::service::mlmodel::v1::InferRequest* /*request*/, ::viam::service::mlmodel::v1::InferResponse* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedInfer(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::viam::service::mlmodel::v1::InferRequest,::viam::service::mlmodel::v1::InferResponse>* server_unary_streamer) = 0;
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_Metadata : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithStreamedUnaryMethod_Metadata() {
      ::grpc::Service::MarkMethodStreamed(1,
        new ::grpc::internal::StreamedUnaryHandler<
          ::viam::service::mlmodel::v1::MetadataRequest, ::viam::service::mlmodel::v1::MetadataResponse>(
            [this](::grpc_impl::ServerContext* context,
                   ::grpc_impl::ServerUnaryStreamer<
                     ::viam::service::mlmodel::v1::MetadataRequest, ::viam::service::mlmodel::v1::MetadataResponse>* streamer) {
                       return this->StreamedMetadata(context,
                         streamer);
                  }));
    }
    ~WithStreamedUnaryMethod_Metadata() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status Metadata(::grpc::ServerContext* /*context*/, const ::viam::service::mlmodel::v1::MetadataRequest* /*request*/, ::viam::service::mlmodel::v1::MetadataResponse* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedMetadata(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::viam::service::mlmodel::v1::MetadataRequest,::viam::service::mlmodel::v1::MetadataResponse>* server_unary_streamer) = 0;
  };
  typedef WithStreamedUnaryMethod_Infer<WithStreamedUnaryMethod_Metadata<Service > > StreamedUnaryService;
  typedef Service SplitStreamedService;
  typedef WithStreamedUnaryMethod_Infer<WithStreamedUnaryMethod_Metadata<Service > > StreamedService;
};

}  // namespace v1
}  // namespace mlmodel
}  // namespace service
}  // namespace viam


#endif  // GRPC_service_2fmlmodel_2fv1_2fmlmodel_2eproto__INCLUDED
